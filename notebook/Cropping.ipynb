{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/train_labels.csv\"\n",
    "csv_file_2 = \"../data/train_labels_2.csv\"\n",
    "\n",
    "df_1 = pd.read_csv(csv_file)\n",
    "df_2 = pd.read_csv(csv_file_2)\n",
    "df = pd.concat([df_1, df_2], ignore_index=True, )\n",
    "df.rename(columns={'Bags used': 'bags_used', 'Pothole number': 'pothole_number'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = \"../data/train_annotations/\"\n",
    "annotations_folder_2 = \"../data/train_annotations_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List to store the extracted data\n",
    "data = []\n",
    "\n",
    "# Loop through each annotation file\n",
    "for file_name in os.listdir(annotations_folder):\n",
    "    if file_name.endswith('.txt'):\n",
    "        image_name = file_name.replace('.txt', '')  # Assuming image has the same name as the annotation file\n",
    "        \n",
    "        # Open and read the annotation file\n",
    "        with open(os.path.join(annotations_folder, file_name), 'r') as file:\n",
    "            for line in file:\n",
    "                # Split the line into its components\n",
    "                class_id, x_center, y_center, width, height = line.strip().split()\n",
    "                \n",
    "                # Append the data to the list\n",
    "                data.append({\n",
    "                    'image_name': image_name,\n",
    "                    'class_id': int(class_id),\n",
    "                    'x_center': float(x_center),\n",
    "                    'y_center': float(y_center),\n",
    "                    'width': float(width),\n",
    "                    'height': float(height)\n",
    "                })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "anno = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_name  class_id  x_center  y_center     width    height\n",
      "0       p930         0  0.449839  0.499142  0.799943  0.998284\n",
      "1       p930         1  0.550746  0.162950  0.071658  0.325900\n",
      "2       p924         1  0.777287  0.467410  0.445397  0.049743\n",
      "3       p924         0  0.519282  0.546312  0.917953  0.704974\n",
      "4        p58         0  0.481026  0.474271  0.483542  0.667238\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# Loop through each annotation file\n",
    "for file_name in os.listdir(annotations_folder_2):\n",
    "    if file_name.endswith('.txt'):\n",
    "        image_name = file_name.replace('.txt', '')  # Assuming image has the same name as the annotation file\n",
    "        \n",
    "        # Open and read the annotation file\n",
    "        with open(os.path.join(annotations_folder_2, file_name), 'r') as file:\n",
    "            for line in file:\n",
    "                # Split the line into its components\n",
    "                class_id, x_center, y_center, width, height = line.strip().split()\n",
    "                \n",
    "                # Append the data to the list\n",
    "                data.append({\n",
    "                    'image_name': image_name,\n",
    "                    'class_id': int(class_id),\n",
    "                    'x_center': float(x_center),\n",
    "                    'y_center': float(y_center),\n",
    "                    'width': float(width),\n",
    "                    'height': float(height)\n",
    "                })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "anno_2 = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(anno_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pothole_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>0.562607</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540652</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>0.560892</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576672</td>\n",
       "      <td>0.540309</td>\n",
       "      <td>0.564322</td>\n",
       "      <td>0.174957</td>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387135</td>\n",
       "      <td>0.484563</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.053173</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439451</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.372213</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>p1663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455288</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>p55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>0.923516</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>p55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>0.435678</td>\n",
       "      <td>0.334832</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>p929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>p929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284582</td>\n",
       "      <td>0.493139</td>\n",
       "      <td>0.567462</td>\n",
       "      <td>0.073756</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1721 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  class_id  x_center  y_center     width    height  \\\n",
       "0         p1336         1  0.634134  0.553173  0.562607  0.094340   \n",
       "1         p1108         0  0.540652  0.533448  0.560892  0.463122   \n",
       "2         p1108         1  0.576672  0.540309  0.564322  0.174957   \n",
       "3         p1120         1  0.387135  0.484563  0.596913  0.053173   \n",
       "4         p1120         0  0.439451  0.510292  0.372213  0.313894   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "1716      p1663         1  0.455288  0.472034  0.727885  0.073593   \n",
       "1717        p55         0  0.461758  0.451115  0.923516  0.356775   \n",
       "1718        p55         1  0.190507  0.435678  0.334832  0.027444   \n",
       "1719       p929         0  0.528169  0.550600  0.782471  0.874786   \n",
       "1720       p929         1  0.284582  0.493139  0.567462  0.073756   \n",
       "\n",
       "      pothole_number  \n",
       "0               1336  \n",
       "1               1108  \n",
       "2               1108  \n",
       "3               1120  \n",
       "4               1120  \n",
       "...              ...  \n",
       "1716            1663  \n",
       "1717              55  \n",
       "1718              55  \n",
       "1719             929  \n",
       "1720             929  \n",
       "\n",
       "[1721 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.concat([anno, anno_2], ignore_index=True, )\n",
    "annotations['pothole_number'] = annotations['image_name'].str.replace('p', '').astype(int)\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pothole_number</th>\n",
       "      <th>Bags used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pothole_number  Bags used \n",
       "263             929         1.0\n",
       "833             929         1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['pothole_number'] == 929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df_annotations = annotations.merge(df,on='pothole_number', how=\"inner\", suffixes=('', '_df'))\n",
    "df_annotations['img_file'] = 'p' + df_annotations['pothole_number'].astype(str) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pothole_number</th>\n",
       "      <th>Bags used</th>\n",
       "      <th>img_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>0.562607</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1336</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1336.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540652</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>0.560892</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576672</td>\n",
       "      <td>0.540309</td>\n",
       "      <td>0.564322</td>\n",
       "      <td>0.174957</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387135</td>\n",
       "      <td>0.484563</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.053173</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439451</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.372213</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>p1663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455288</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>1663</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p1663.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>p55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>0.923516</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>p55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>0.435678</td>\n",
       "      <td>0.334832</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>p929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>p929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284582</td>\n",
       "      <td>0.493139</td>\n",
       "      <td>0.567462</td>\n",
       "      <td>0.073756</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1519 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  class_id  x_center  y_center     width    height  \\\n",
       "0         p1336         1  0.634134  0.553173  0.562607  0.094340   \n",
       "1         p1108         0  0.540652  0.533448  0.560892  0.463122   \n",
       "2         p1108         1  0.576672  0.540309  0.564322  0.174957   \n",
       "3         p1120         1  0.387135  0.484563  0.596913  0.053173   \n",
       "4         p1120         0  0.439451  0.510292  0.372213  0.313894   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "1514      p1663         1  0.455288  0.472034  0.727885  0.073593   \n",
       "1515        p55         0  0.461758  0.451115  0.923516  0.356775   \n",
       "1516        p55         1  0.190507  0.435678  0.334832  0.027444   \n",
       "1517       p929         0  0.528169  0.550600  0.782471  0.874786   \n",
       "1518       p929         1  0.284582  0.493139  0.567462  0.073756   \n",
       "\n",
       "      pothole_number  Bags used    img_file  \n",
       "0               1336        0.25  p1336.jpg  \n",
       "1               1108        0.50  p1108.jpg  \n",
       "2               1108        0.50  p1108.jpg  \n",
       "3               1120        0.25  p1120.jpg  \n",
       "4               1120        0.25  p1120.jpg  \n",
       "...              ...         ...        ...  \n",
       "1514            1663        1.00  p1663.jpg  \n",
       "1515              55        2.00    p55.jpg  \n",
       "1516              55        2.00    p55.jpg  \n",
       "1517             929        1.00   p929.jpg  \n",
       "1518             929        1.00   p929.jpg  \n",
       "\n",
       "[1519 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = [] \n",
    "for file in df_annotations['img_file']:\n",
    "    name = '../data/train_images/' + file \n",
    "    name_2 = '../data/train_images_2/' + file \n",
    "    if os.path.exists(name):\n",
    "        valid.append(file)\n",
    "    elif os.path.exists(name_2):\n",
    "        valid.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1519"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pothole_number</th>\n",
       "      <th>Bags used</th>\n",
       "      <th>img_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>0.562607</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1336</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1336.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540652</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>0.560892</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576672</td>\n",
       "      <td>0.540309</td>\n",
       "      <td>0.564322</td>\n",
       "      <td>0.174957</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387135</td>\n",
       "      <td>0.484563</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.053173</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439451</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.372213</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>p1663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455288</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>1663</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p1663.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>p55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>0.923516</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>p55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>0.435678</td>\n",
       "      <td>0.334832</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>p929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>p929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284582</td>\n",
       "      <td>0.493139</td>\n",
       "      <td>0.567462</td>\n",
       "      <td>0.073756</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1519 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  class_id  x_center  y_center     width    height  \\\n",
       "0         p1336         1  0.634134  0.553173  0.562607  0.094340   \n",
       "1         p1108         0  0.540652  0.533448  0.560892  0.463122   \n",
       "2         p1108         1  0.576672  0.540309  0.564322  0.174957   \n",
       "3         p1120         1  0.387135  0.484563  0.596913  0.053173   \n",
       "4         p1120         0  0.439451  0.510292  0.372213  0.313894   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "1514      p1663         1  0.455288  0.472034  0.727885  0.073593   \n",
       "1515        p55         0  0.461758  0.451115  0.923516  0.356775   \n",
       "1516        p55         1  0.190507  0.435678  0.334832  0.027444   \n",
       "1517       p929         0  0.528169  0.550600  0.782471  0.874786   \n",
       "1518       p929         1  0.284582  0.493139  0.567462  0.073756   \n",
       "\n",
       "      pothole_number  Bags used    img_file  \n",
       "0               1336        0.25  p1336.jpg  \n",
       "1               1108        0.50  p1108.jpg  \n",
       "2               1108        0.50  p1108.jpg  \n",
       "3               1120        0.25  p1120.jpg  \n",
       "4               1120        0.25  p1120.jpg  \n",
       "...              ...         ...        ...  \n",
       "1514            1663        1.00  p1663.jpg  \n",
       "1515              55        2.00    p55.jpg  \n",
       "1516              55        2.00    p55.jpg  \n",
       "1517             929        1.00   p929.jpg  \n",
       "1518             929        1.00   p929.jpg  \n",
       "\n",
       "[1519 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = df_annotations[df_annotations['img_file'].isin(valid)]\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_bbox(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_min = (x_center - width / 2) * img_width\n",
    "    x_max = (x_center + width / 2) * img_width\n",
    "    y_min = (y_center - height / 2) * img_height\n",
    "    y_max = (y_center + height / 2) * img_height\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "# Calculate the diagonal length of the bounding box for `class_id` 1\n",
    "def calculate_stick_size(row, img_width, img_height):\n",
    "    if (row['class_id'] != 1):\n",
    "        return 0\n",
    "    x_min, y_min, x_max, y_max = yolo_to_bbox(\n",
    "        row['x_center'], row['y_center'], row['width'], row['height'], img_width, img_height\n",
    "    )\n",
    "    return np.sqrt((x_max - x_min) ** 2 + (y_max - y_min) ** 2)\n",
    "\n",
    "# Example function to load an image and get its dimensions\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "# Add a column with stick sizes\n",
    "df_annotations['stick_size'] = df_annotations.apply(\n",
    "    lambda row: calculate_stick_size(row, *get_image_size(f'../data/train_all/{row[\"img_file\"]}')),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations['stick_size'] = df_annotations.groupby('pothole_number')['stick_size'].transform(\n",
    "    lambda x: x.replace(0, x.max())\n",
    ")\n",
    "\n",
    "# If stick_size is still zero, populate it with the mean of non-zero stick_size values\n",
    "mean_stick_size = df_annotations['stick_size'].replace(0, np.nan).mean()\n",
    "df_annotations['stick_size'] = df_annotations['stick_size'].replace(0, mean_stick_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations['has_pothole'] = df_annotations.groupby('pothole_number')['class_id'].transform(lambda x: (x == 0).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotations = df_annotations.reset_index(drop=True)\n",
    "df_annotations['stick_size'].idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name             p1601\n",
      "class_id                   0\n",
      "x_center            0.427885\n",
      "y_center                 0.5\n",
      "width               0.848077\n",
      "height              0.997321\n",
      "pothole_number          1601\n",
      "Bags used                0.5\n",
      "img_file           p1601.jpg\n",
      "stick_size        842.645863\n",
      "has_pothole             True\n",
      "Name: 1275, dtype: object\n"
     ]
    }
   ],
   "source": [
    "idx_max = df_annotations['stick_size'].idxmax()\n",
    "if idx_max in df_annotations.index:\n",
    "    row_max = df_annotations.loc[idx_max]\n",
    "    print(row_max)\n",
    "else:\n",
    "    print(f\"Index {idx_max} not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pothole_number</th>\n",
       "      <th>Bags used</th>\n",
       "      <th>img_file</th>\n",
       "      <th>stick_size</th>\n",
       "      <th>has_pothole</th>\n",
       "      <th>scale_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>0.553173</td>\n",
       "      <td>0.562607</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>1336</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1336.jpg</td>\n",
       "      <td>215.634563</td>\n",
       "      <td>False</td>\n",
       "      <td>1.854990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540652</td>\n",
       "      <td>0.533448</td>\n",
       "      <td>0.560892</td>\n",
       "      <td>0.463122</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "      <td>223.330280</td>\n",
       "      <td>True</td>\n",
       "      <td>1.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576672</td>\n",
       "      <td>0.540309</td>\n",
       "      <td>0.564322</td>\n",
       "      <td>0.174957</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.50</td>\n",
       "      <td>p1108.jpg</td>\n",
       "      <td>223.330280</td>\n",
       "      <td>True</td>\n",
       "      <td>1.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387135</td>\n",
       "      <td>0.484563</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.053173</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "      <td>226.526572</td>\n",
       "      <td>True</td>\n",
       "      <td>1.765797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439451</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.372213</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p1120.jpg</td>\n",
       "      <td>226.526572</td>\n",
       "      <td>True</td>\n",
       "      <td>1.765797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>p1663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455288</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>1663</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p1663.jpg</td>\n",
       "      <td>690.079562</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>p55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>0.923516</td>\n",
       "      <td>0.356775</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "      <td>117.200459</td>\n",
       "      <td>True</td>\n",
       "      <td>3.412956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>p55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>0.435678</td>\n",
       "      <td>0.334832</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>p55.jpg</td>\n",
       "      <td>117.200459</td>\n",
       "      <td>True</td>\n",
       "      <td>3.412956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>p929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "      <td>309.195260</td>\n",
       "      <td>True</td>\n",
       "      <td>1.293681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>p929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284582</td>\n",
       "      <td>0.493139</td>\n",
       "      <td>0.567462</td>\n",
       "      <td>0.073756</td>\n",
       "      <td>929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>p929.jpg</td>\n",
       "      <td>309.195260</td>\n",
       "      <td>True</td>\n",
       "      <td>1.293681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1519 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  class_id  x_center  y_center     width    height  \\\n",
       "0         p1336         1  0.634134  0.553173  0.562607  0.094340   \n",
       "1         p1108         0  0.540652  0.533448  0.560892  0.463122   \n",
       "2         p1108         1  0.576672  0.540309  0.564322  0.174957   \n",
       "3         p1120         1  0.387135  0.484563  0.596913  0.053173   \n",
       "4         p1120         0  0.439451  0.510292  0.372213  0.313894   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "1514      p1663         1  0.455288  0.472034  0.727885  0.073593   \n",
       "1515        p55         0  0.461758  0.451115  0.923516  0.356775   \n",
       "1516        p55         1  0.190507  0.435678  0.334832  0.027444   \n",
       "1517       p929         0  0.528169  0.550600  0.782471  0.874786   \n",
       "1518       p929         1  0.284582  0.493139  0.567462  0.073756   \n",
       "\n",
       "      pothole_number  Bags used    img_file  stick_size  has_pothole  \\\n",
       "0               1336        0.25  p1336.jpg  215.634563        False   \n",
       "1               1108        0.50  p1108.jpg  223.330280         True   \n",
       "2               1108        0.50  p1108.jpg  223.330280         True   \n",
       "3               1120        0.25  p1120.jpg  226.526572         True   \n",
       "4               1120        0.25  p1120.jpg  226.526572         True   \n",
       "...              ...         ...        ...         ...          ...   \n",
       "1514            1663        1.00  p1663.jpg  690.079562         True   \n",
       "1515              55        2.00    p55.jpg  117.200459         True   \n",
       "1516              55        2.00    p55.jpg  117.200459         True   \n",
       "1517             929        1.00   p929.jpg  309.195260         True   \n",
       "1518             929        1.00   p929.jpg  309.195260         True   \n",
       "\n",
       "      scale_factor  \n",
       "0         1.854990  \n",
       "1         1.791069  \n",
       "2         1.791069  \n",
       "3         1.765797  \n",
       "4         1.765797  \n",
       "...            ...  \n",
       "1514      0.579643  \n",
       "1515      3.412956  \n",
       "1516      3.412956  \n",
       "1517      1.293681  \n",
       "1518      1.293681  \n",
       "\n",
       "[1519 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stick_min = df_annotations['stick_size'].mean()\n",
    "df_annotations['scale_factor'] = (400 / df_annotations['stick_size'])\n",
    "\n",
    "# Convert scale_factor to integer type if needed\n",
    "#df_annotations['scale_factor'] = df_annotations['scale_factor'].astype(int)\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path, scale_factor, output_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        # Calculate new size\n",
    "        width, height = img.size\n",
    "        new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "        \n",
    "        # Resize and save image\n",
    "        img_resized = img.resize(new_size, Image.LANCZOS)\n",
    "        img_resized.save(output_path)  # Save resized image\n",
    "\n",
    "# Define a target size for the stick\n",
    "for index, row in df_annotations.iterrows():\n",
    "    image_path = f\"../data/train_all/{row['img_file']}\"\n",
    "    output_path = f\"../data/cropped_images/{row['img_file']}\"\n",
    "    scale_factor = row['scale_factor']\n",
    "    \n",
    "    resize_image(image_path, scale_factor, output_path)\n",
    "\n",
    "# Resize all images to match the target size of the stick\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_pad_image(image_path, output_path, target_size=(512, 512), max_image_size=None):\n",
    "    with Image.open(image_path) as img:\n",
    "        # Calculate scaling factor based on the largest image\n",
    "        if max_image_size is None:\n",
    "            max_image_size = max(img.size)\n",
    "        \n",
    "        scale_factor = target_size[0] / max_image_size\n",
    "        \n",
    "        # Resize the image while keeping aspect ratio\n",
    "        new_size = (int(img.width * scale_factor), int(img.height * scale_factor))\n",
    "        img_resized = img.resize(new_size, Image.LANCZOS)\n",
    "        \n",
    "        # Create a new image with a black background\n",
    "        new_img = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
    "        \n",
    "        # Calculate padding\n",
    "        padding_x = (target_size[0] - new_size[0]) // 2\n",
    "        padding_y = (target_size[1] - new_size[1]) // 2\n",
    "        \n",
    "        # Paste the resized image onto the black background\n",
    "        new_img.paste(img_resized, (padding_x, padding_y))\n",
    "        \n",
    "        # Save the new image\n",
    "        new_img.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_paths = []\n",
    "for index, row in df_annotations.iterrows():\n",
    "    image_paths.append(f\"../data/cropped_images/{row['img_file']}\")\n",
    "output_folder = \"../data/padded_images/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find the largest image size\n",
    "max_image_size = max([max(Image.open(image_path).size) for image_path in image_paths])\n",
    "# Resize and pad each image\n",
    "for image_path in image_paths:\n",
    "    output_path = os.path.join(output_folder, f\"resized_{os.path.basename(image_path)}\")\n",
    "    resize_and_pad_image(image_path, output_path, target_size=(512, 512), max_image_size=max_image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2936808920974263"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_randomness_to_colors_tf(image):\n",
    "    color_shift_range = tf.random.uniform([], 0, 15, dtype=tf.float32)\n",
    "\n",
    "    # Convert the image to a float32 tensor and normalize the values to [0, 1]\n",
    "    img_tensor = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # Generate random shifts for each color channel\n",
    "    random_shift = tf.random.uniform(tf.shape(img_tensor), -color_shift_range/255.0, color_shift_range/255.0)\n",
    "\n",
    "    # Add the random shift and clip values to stay within valid range [0, 1]\n",
    "    img_tensor = tf.clip_by_value(img_tensor + random_shift, 0.0, 1.0)\n",
    "\n",
    "    # Convert back to the original data type\n",
    "    img_tensor = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
    "\n",
    "    return img_tensor\n",
    "class Augment(tf.keras.layers.Layer):\n",
    "    def __init__(self, contrast_range=[0.4, 1.5], \n",
    "                 brightness_delta=[-0.4, 0.3],\n",
    "                 hue_delta=[-0.1, 0.1],\n",
    "                 jpeg_qual = [40,100],\n",
    "                 **kwargs):\n",
    "        super(Augment, self).__init__(**kwargs)\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_delta = brightness_delta\n",
    "        self.hue_delta = hue_delta\n",
    "        self.jpeg_qual = jpeg_qual\n",
    "    \n",
    "    def ensure_rank_4(self, images):\n",
    "        \"\"\"Ensure that the images tensor has rank 4.\"\"\"\n",
    "        if len(images.shape) == 3:\n",
    "            # If the image is rank 3 (height, width, channels), add a batch dimension\n",
    "            images = tf.expand_dims(images, axis=0)\n",
    "        elif len(images.shape) == 5:\n",
    "            # If the image is rank 5 (batch_size, height, width, channels, extra), squeeze out the extra dimension\n",
    "            images = tf.squeeze(images, axis=-1)\n",
    "        return images\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        if not training:\n",
    "            return images\n",
    "        \n",
    "        images = self.ensure_rank_4(images)\n",
    "        \n",
    "        contrast = np.random.uniform(\n",
    "            self.contrast_range[0], self.contrast_range[1])\n",
    "        brightness = np.random.uniform(\n",
    "            self.brightness_delta[0], self.brightness_delta[1])\n",
    "        hue = np.random.uniform(\n",
    "            self.hue_delta[0], self.hue_delta[1])\n",
    "        jpeg = random.randint(\n",
    "            self.jpeg_qual[0], self.jpeg_qual[1])\n",
    "        flip_u = random.randint(0,2)\n",
    "        flip_l = random.randint(0,2)\n",
    "        \n",
    "        contr = random.randint(0,3)\n",
    "        bright = random.randint(0,3)\n",
    "\n",
    "        ad_hue = random.randint(0,3)\n",
    "        j_q = random.randint(0,2)\n",
    "\n",
    "        rand_col = random.randint(0,4)\n",
    "        soft = random.randint(0,2)\n",
    "\n",
    "        rot = random.randint(0, 3)\n",
    "\n",
    "        if (contr == 1) :images = tf.image.adjust_contrast(images, contrast)\n",
    "        if (bright == 1) :images = tf.image.adjust_brightness(images, brightness)\n",
    "        images = tf.clip_by_value(images, 0, 1)\n",
    "        if (ad_hue == 1) :images = tf.image.adjust_hue(images, hue)\n",
    "        #if (j_q== 1) :images = tf.image.adjust_jpeg_quality(images, jpeg, dct_method='')\n",
    "        if (rand_col == 1) :images = add_randomness_to_colors_tf(images)\n",
    "        #if (soft == 1) :images = soften_edges_tf(images)\n",
    "        if (flip_l == 1) : images = tf.image.flip_left_right(images)\n",
    "        if (flip_u == 1) : images = tf.image.flip_up_down(images)\n",
    "        if (rot == 1) : images =tf.image.rot90(images)\n",
    "\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define image dimensions\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "# Preprocess images and load into arrays\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_width, img_height))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess images\n",
    "X = np.array([preprocess_image('../data/padded_images/resized_' + file) for file in valid_df['img_file']])\n",
    "y = valid_df['Bags used '].values\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train_un, y_test_un = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = scaler.fit_transform(y_train_un.reshape(-1, 1)).flatten()\n",
    "y_test = scaler.transform(y_test_un.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=50,          # Stop after 5 epochs of no improvement\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffanschoonbee/Documents/Studies/Hackathon/StandardBankHackathon/notebook/venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augment_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Augment</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61504</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,968,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augment_30 (\u001b[38;5;33mAugment\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m4,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61504\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m1,968,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,974,225</span> (7.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,974,225\u001b[0m (7.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,974,225</span> (7.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,974,225\u001b[0m (7.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augment_layer = Augment()\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(256, 256, 3)),  # Replace with your input image size\n",
    "    augment_layer,  # Add the augmentation layer here\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Regression output for predicting 'bags_used'\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - loss: 0.0548 - mean_absolute_error: 0.0998 - val_loss: 0.0030 - val_mean_absolute_error: 0.0341\n",
      "Epoch 2/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0078 - mean_absolute_error: 0.0404 - val_loss: 0.0033 - val_mean_absolute_error: 0.0363\n",
      "Epoch 3/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0081 - mean_absolute_error: 0.0448 - val_loss: 0.0028 - val_mean_absolute_error: 0.0336\n",
      "Epoch 4/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 146ms/step - loss: 0.0065 - mean_absolute_error: 0.0398 - val_loss: 0.0033 - val_mean_absolute_error: 0.0367\n",
      "Epoch 5/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0094 - mean_absolute_error: 0.0458 - val_loss: 0.0032 - val_mean_absolute_error: 0.0349\n",
      "Epoch 6/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0078 - mean_absolute_error: 0.0423 - val_loss: 0.0032 - val_mean_absolute_error: 0.0369\n",
      "Epoch 7/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - loss: 0.0048 - mean_absolute_error: 0.0403 - val_loss: 0.0032 - val_mean_absolute_error: 0.0345\n",
      "Epoch 8/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0051 - mean_absolute_error: 0.0376 - val_loss: 0.0032 - val_mean_absolute_error: 0.0360\n",
      "Epoch 9/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 136ms/step - loss: 0.0037 - mean_absolute_error: 0.0359 - val_loss: 0.0031 - val_mean_absolute_error: 0.0353\n",
      "Epoch 10/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 136ms/step - loss: 0.0031 - mean_absolute_error: 0.0344 - val_loss: 0.0030 - val_mean_absolute_error: 0.0332\n",
      "Epoch 11/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0050 - mean_absolute_error: 0.0370 - val_loss: 0.0028 - val_mean_absolute_error: 0.0325\n",
      "Epoch 12/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0049 - mean_absolute_error: 0.0359 - val_loss: 0.0027 - val_mean_absolute_error: 0.0323\n",
      "Epoch 13/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 0.0053 - mean_absolute_error: 0.0377 - val_loss: 0.0028 - val_mean_absolute_error: 0.0312\n",
      "Epoch 14/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0026 - mean_absolute_error: 0.0322 - val_loss: 0.0027 - val_mean_absolute_error: 0.0310\n",
      "Epoch 15/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 0.0041 - mean_absolute_error: 0.0346 - val_loss: 0.0027 - val_mean_absolute_error: 0.0296\n",
      "Epoch 16/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - loss: 0.0057 - mean_absolute_error: 0.0387 - val_loss: 0.0028 - val_mean_absolute_error: 0.0316\n",
      "Epoch 17/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 0.0048 - mean_absolute_error: 0.0368 - val_loss: 0.0027 - val_mean_absolute_error: 0.0315\n",
      "Epoch 18/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - loss: 0.0046 - mean_absolute_error: 0.0359 - val_loss: 0.0027 - val_mean_absolute_error: 0.0306\n",
      "Epoch 19/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 0.0057 - mean_absolute_error: 0.0369 - val_loss: 0.0027 - val_mean_absolute_error: 0.0308\n",
      "Epoch 20/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - loss: 0.0032 - mean_absolute_error: 0.0325 - val_loss: 0.0025 - val_mean_absolute_error: 0.0322\n",
      "Epoch 21/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - loss: 0.0050 - mean_absolute_error: 0.0368 - val_loss: 0.0027 - val_mean_absolute_error: 0.0299\n",
      "Epoch 22/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 0.0037 - mean_absolute_error: 0.0326 - val_loss: 0.0030 - val_mean_absolute_error: 0.0323\n",
      "Epoch 23/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0065 - mean_absolute_error: 0.0391 - val_loss: 0.0025 - val_mean_absolute_error: 0.0305\n",
      "Epoch 24/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0056 - mean_absolute_error: 0.0353 - val_loss: 0.0026 - val_mean_absolute_error: 0.0324\n",
      "Epoch 25/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 0.0039 - mean_absolute_error: 0.0341 - val_loss: 0.0026 - val_mean_absolute_error: 0.0311\n",
      "Epoch 26/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - loss: 0.0041 - mean_absolute_error: 0.0313 - val_loss: 0.0024 - val_mean_absolute_error: 0.0311\n",
      "Epoch 27/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0050 - mean_absolute_error: 0.0355 - val_loss: 0.0024 - val_mean_absolute_error: 0.0291\n",
      "Epoch 28/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - loss: 0.0038 - mean_absolute_error: 0.0306 - val_loss: 0.0027 - val_mean_absolute_error: 0.0298\n",
      "Epoch 29/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0036 - mean_absolute_error: 0.0336 - val_loss: 0.0028 - val_mean_absolute_error: 0.0325\n",
      "Epoch 30/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0052 - mean_absolute_error: 0.0365 - val_loss: 0.0026 - val_mean_absolute_error: 0.0292\n",
      "Epoch 31/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0036 - mean_absolute_error: 0.0331 - val_loss: 0.0025 - val_mean_absolute_error: 0.0309\n",
      "Epoch 32/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0038 - mean_absolute_error: 0.0329 - val_loss: 0.0027 - val_mean_absolute_error: 0.0300\n",
      "Epoch 33/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0042 - mean_absolute_error: 0.0343 - val_loss: 0.0028 - val_mean_absolute_error: 0.0303\n",
      "Epoch 34/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0055 - mean_absolute_error: 0.0354 - val_loss: 0.0026 - val_mean_absolute_error: 0.0302\n",
      "Epoch 35/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0030 - mean_absolute_error: 0.0318 - val_loss: 0.0024 - val_mean_absolute_error: 0.0298\n",
      "Epoch 36/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0025 - mean_absolute_error: 0.0292 - val_loss: 0.0027 - val_mean_absolute_error: 0.0307\n",
      "Epoch 37/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0059 - mean_absolute_error: 0.0377 - val_loss: 0.0027 - val_mean_absolute_error: 0.0317\n",
      "Epoch 38/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0040 - mean_absolute_error: 0.0345 - val_loss: 0.0024 - val_mean_absolute_error: 0.0307\n",
      "Epoch 39/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0041 - mean_absolute_error: 0.0327 - val_loss: 0.0026 - val_mean_absolute_error: 0.0327\n",
      "Epoch 40/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0050 - mean_absolute_error: 0.0350 - val_loss: 0.0024 - val_mean_absolute_error: 0.0297\n",
      "Epoch 41/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0069 - mean_absolute_error: 0.0373 - val_loss: 0.0024 - val_mean_absolute_error: 0.0312\n",
      "Epoch 42/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0042 - mean_absolute_error: 0.0327 - val_loss: 0.0025 - val_mean_absolute_error: 0.0290\n",
      "Epoch 43/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - loss: 0.0049 - mean_absolute_error: 0.0340 - val_loss: 0.0025 - val_mean_absolute_error: 0.0296\n",
      "Epoch 44/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0045 - mean_absolute_error: 0.0323 - val_loss: 0.0026 - val_mean_absolute_error: 0.0290\n",
      "Epoch 45/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0025 - mean_absolute_error: 0.0292 - val_loss: 0.0024 - val_mean_absolute_error: 0.0274\n",
      "Epoch 46/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0037 - mean_absolute_error: 0.0296 - val_loss: 0.0025 - val_mean_absolute_error: 0.0289\n",
      "Epoch 47/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - loss: 0.0028 - mean_absolute_error: 0.0291 - val_loss: 0.0025 - val_mean_absolute_error: 0.0287\n",
      "Epoch 48/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 0.0038 - mean_absolute_error: 0.0314 - val_loss: 0.0027 - val_mean_absolute_error: 0.0280\n",
      "Epoch 49/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0035 - mean_absolute_error: 0.0309 - val_loss: 0.0026 - val_mean_absolute_error: 0.0280\n",
      "Epoch 50/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0037 - mean_absolute_error: 0.0311 - val_loss: 0.0025 - val_mean_absolute_error: 0.0280\n",
      "Epoch 51/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0032 - mean_absolute_error: 0.0287 - val_loss: 0.0025 - val_mean_absolute_error: 0.0288\n",
      "Epoch 52/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0027 - mean_absolute_error: 0.0306 - val_loss: 0.0025 - val_mean_absolute_error: 0.0274\n",
      "Epoch 53/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0046 - mean_absolute_error: 0.0304 - val_loss: 0.0025 - val_mean_absolute_error: 0.0288\n",
      "Epoch 54/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0067 - mean_absolute_error: 0.0337 - val_loss: 0.0023 - val_mean_absolute_error: 0.0281\n",
      "Epoch 55/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0076 - mean_absolute_error: 0.0376 - val_loss: 0.0026 - val_mean_absolute_error: 0.0290\n",
      "Epoch 56/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0023 - mean_absolute_error: 0.0297 - val_loss: 0.0024 - val_mean_absolute_error: 0.0291\n",
      "Epoch 57/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0046 - mean_absolute_error: 0.0322 - val_loss: 0.0026 - val_mean_absolute_error: 0.0278\n",
      "Epoch 58/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0029 - mean_absolute_error: 0.0278 - val_loss: 0.0024 - val_mean_absolute_error: 0.0294\n",
      "Epoch 59/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0037 - mean_absolute_error: 0.0303 - val_loss: 0.0025 - val_mean_absolute_error: 0.0276\n",
      "Epoch 60/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0031 - mean_absolute_error: 0.0302 - val_loss: 0.0026 - val_mean_absolute_error: 0.0288\n",
      "Epoch 61/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0034 - mean_absolute_error: 0.0303 - val_loss: 0.0024 - val_mean_absolute_error: 0.0282\n",
      "Epoch 62/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - loss: 0.0034 - mean_absolute_error: 0.0306 - val_loss: 0.0024 - val_mean_absolute_error: 0.0274\n",
      "Epoch 63/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0029 - mean_absolute_error: 0.0277 - val_loss: 0.0023 - val_mean_absolute_error: 0.0281\n",
      "Epoch 64/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0032 - mean_absolute_error: 0.0296 - val_loss: 0.0023 - val_mean_absolute_error: 0.0261\n",
      "Epoch 65/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0028 - mean_absolute_error: 0.0283 - val_loss: 0.0023 - val_mean_absolute_error: 0.0268\n",
      "Epoch 66/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0016 - mean_absolute_error: 0.0261 - val_loss: 0.0024 - val_mean_absolute_error: 0.0268\n",
      "Epoch 67/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0024 - mean_absolute_error: 0.0270 - val_loss: 0.0023 - val_mean_absolute_error: 0.0275\n",
      "Epoch 68/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - loss: 0.0038 - mean_absolute_error: 0.0274 - val_loss: 0.0022 - val_mean_absolute_error: 0.0259\n",
      "Epoch 69/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0027 - mean_absolute_error: 0.0284 - val_loss: 0.0023 - val_mean_absolute_error: 0.0269\n",
      "Epoch 70/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0033 - mean_absolute_error: 0.0284 - val_loss: 0.0025 - val_mean_absolute_error: 0.0292\n",
      "Epoch 71/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0031 - mean_absolute_error: 0.0298 - val_loss: 0.0022 - val_mean_absolute_error: 0.0266\n",
      "Epoch 72/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0021 - mean_absolute_error: 0.0268 - val_loss: 0.0021 - val_mean_absolute_error: 0.0261\n",
      "Epoch 73/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0029 - mean_absolute_error: 0.0287 - val_loss: 0.0022 - val_mean_absolute_error: 0.0256\n",
      "Epoch 74/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0026 - mean_absolute_error: 0.0260 - val_loss: 0.0021 - val_mean_absolute_error: 0.0271\n",
      "Epoch 75/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0030 - mean_absolute_error: 0.0279 - val_loss: 0.0023 - val_mean_absolute_error: 0.0277\n",
      "Epoch 76/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0040 - mean_absolute_error: 0.0297 - val_loss: 0.0024 - val_mean_absolute_error: 0.0280\n",
      "Epoch 77/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0036 - mean_absolute_error: 0.0298 - val_loss: 0.0021 - val_mean_absolute_error: 0.0264\n",
      "Epoch 78/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0020 - mean_absolute_error: 0.0263 - val_loss: 0.0022 - val_mean_absolute_error: 0.0260\n",
      "Epoch 79/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0029 - mean_absolute_error: 0.0268 - val_loss: 0.0021 - val_mean_absolute_error: 0.0271\n",
      "Epoch 80/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0037 - mean_absolute_error: 0.0293 - val_loss: 0.0021 - val_mean_absolute_error: 0.0270\n",
      "Epoch 81/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0026 - mean_absolute_error: 0.0278 - val_loss: 0.0020 - val_mean_absolute_error: 0.0250\n",
      "Epoch 82/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - loss: 0.0029 - mean_absolute_error: 0.0282 - val_loss: 0.0026 - val_mean_absolute_error: 0.0307\n",
      "Epoch 83/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0028 - mean_absolute_error: 0.0300 - val_loss: 0.0025 - val_mean_absolute_error: 0.0275\n",
      "Epoch 84/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0045 - mean_absolute_error: 0.0320 - val_loss: 0.0029 - val_mean_absolute_error: 0.0311\n",
      "Epoch 85/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0034 - mean_absolute_error: 0.0308 - val_loss: 0.0024 - val_mean_absolute_error: 0.0270\n",
      "Epoch 86/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0037 - mean_absolute_error: 0.0304 - val_loss: 0.0023 - val_mean_absolute_error: 0.0278\n",
      "Epoch 87/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0038 - mean_absolute_error: 0.0296 - val_loss: 0.0023 - val_mean_absolute_error: 0.0267\n",
      "Epoch 88/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0027 - mean_absolute_error: 0.0296 - val_loss: 0.0022 - val_mean_absolute_error: 0.0273\n",
      "Epoch 89/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0040 - mean_absolute_error: 0.0301 - val_loss: 0.0021 - val_mean_absolute_error: 0.0257\n",
      "Epoch 90/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0015 - mean_absolute_error: 0.0241 - val_loss: 0.0022 - val_mean_absolute_error: 0.0255\n",
      "Epoch 91/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - loss: 0.0033 - mean_absolute_error: 0.0269 - val_loss: 0.0024 - val_mean_absolute_error: 0.0284\n",
      "Epoch 92/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - loss: 0.0034 - mean_absolute_error: 0.0290 - val_loss: 0.0023 - val_mean_absolute_error: 0.0266\n",
      "Epoch 93/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - loss: 0.0048 - mean_absolute_error: 0.0322 - val_loss: 0.0021 - val_mean_absolute_error: 0.0267\n",
      "Epoch 94/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - loss: 0.0021 - mean_absolute_error: 0.0261 - val_loss: 0.0020 - val_mean_absolute_error: 0.0255\n",
      "Epoch 95/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0023 - mean_absolute_error: 0.0266 - val_loss: 0.0023 - val_mean_absolute_error: 0.0269\n",
      "Epoch 96/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0025 - mean_absolute_error: 0.0259 - val_loss: 0.0022 - val_mean_absolute_error: 0.0266\n",
      "Epoch 97/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 0.0019 - mean_absolute_error: 0.0250 - val_loss: 0.0022 - val_mean_absolute_error: 0.0257\n",
      "Epoch 98/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 151ms/step - loss: 0.0026 - mean_absolute_error: 0.0273 - val_loss: 0.0022 - val_mean_absolute_error: 0.0265\n",
      "Epoch 99/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0034 - mean_absolute_error: 0.0273 - val_loss: 0.0021 - val_mean_absolute_error: 0.0262\n",
      "Epoch 100/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0028 - mean_absolute_error: 0.0274 - val_loss: 0.0022 - val_mean_absolute_error: 0.0268\n",
      "Epoch 101/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - loss: 0.0028 - mean_absolute_error: 0.0285 - val_loss: 0.0022 - val_mean_absolute_error: 0.0264\n",
      "Epoch 102/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - loss: 0.0030 - mean_absolute_error: 0.0286 - val_loss: 0.0022 - val_mean_absolute_error: 0.0253\n",
      "Epoch 103/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 148ms/step - loss: 0.0031 - mean_absolute_error: 0.0253 - val_loss: 0.0021 - val_mean_absolute_error: 0.0267\n",
      "Epoch 104/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 0.0028 - mean_absolute_error: 0.0265 - val_loss: 0.0021 - val_mean_absolute_error: 0.0251\n",
      "Epoch 105/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - loss: 0.0046 - mean_absolute_error: 0.0287 - val_loss: 0.0020 - val_mean_absolute_error: 0.0244\n",
      "Epoch 106/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 0.0026 - mean_absolute_error: 0.0248 - val_loss: 0.0021 - val_mean_absolute_error: 0.0249\n",
      "Epoch 107/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 180ms/step - loss: 0.0051 - mean_absolute_error: 0.0290 - val_loss: 0.0020 - val_mean_absolute_error: 0.0257\n",
      "Epoch 108/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 153ms/step - loss: 0.0020 - mean_absolute_error: 0.0257 - val_loss: 0.0021 - val_mean_absolute_error: 0.0269\n",
      "Epoch 109/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0021 - mean_absolute_error: 0.0251 - val_loss: 0.0021 - val_mean_absolute_error: 0.0252\n",
      "Epoch 110/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0027 - mean_absolute_error: 0.0278 - val_loss: 0.0023 - val_mean_absolute_error: 0.0267\n",
      "Epoch 111/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0017 - mean_absolute_error: 0.0247 - val_loss: 0.0021 - val_mean_absolute_error: 0.0241\n",
      "Epoch 112/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0025 - mean_absolute_error: 0.0266 - val_loss: 0.0020 - val_mean_absolute_error: 0.0262\n",
      "Epoch 113/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0023 - mean_absolute_error: 0.0253 - val_loss: 0.0020 - val_mean_absolute_error: 0.0246\n",
      "Epoch 114/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0024 - mean_absolute_error: 0.0255 - val_loss: 0.0021 - val_mean_absolute_error: 0.0259\n",
      "Epoch 115/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0032 - mean_absolute_error: 0.0285 - val_loss: 0.0020 - val_mean_absolute_error: 0.0234\n",
      "Epoch 116/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0036 - mean_absolute_error: 0.0275 - val_loss: 0.0020 - val_mean_absolute_error: 0.0248\n",
      "Epoch 117/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - loss: 0.0021 - mean_absolute_error: 0.0256 - val_loss: 0.0020 - val_mean_absolute_error: 0.0228\n",
      "Epoch 118/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - loss: 0.0020 - mean_absolute_error: 0.0261 - val_loss: 0.0020 - val_mean_absolute_error: 0.0233\n",
      "Epoch 119/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0022 - mean_absolute_error: 0.0239 - val_loss: 0.0021 - val_mean_absolute_error: 0.0255\n",
      "Epoch 120/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0024 - mean_absolute_error: 0.0258 - val_loss: 0.0020 - val_mean_absolute_error: 0.0245\n",
      "Epoch 121/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - loss: 0.0062 - mean_absolute_error: 0.0296 - val_loss: 0.0020 - val_mean_absolute_error: 0.0241\n",
      "Epoch 122/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0026 - mean_absolute_error: 0.0236 - val_loss: 0.0021 - val_mean_absolute_error: 0.0231\n",
      "Epoch 123/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - loss: 0.0020 - mean_absolute_error: 0.0240 - val_loss: 0.0019 - val_mean_absolute_error: 0.0240\n",
      "Epoch 124/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - loss: 0.0020 - mean_absolute_error: 0.0240 - val_loss: 0.0020 - val_mean_absolute_error: 0.0235\n",
      "Epoch 125/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - loss: 0.0021 - mean_absolute_error: 0.0252 - val_loss: 0.0018 - val_mean_absolute_error: 0.0255\n",
      "Epoch 126/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - loss: 0.0033 - mean_absolute_error: 0.0273 - val_loss: 0.0020 - val_mean_absolute_error: 0.0262\n",
      "Epoch 127/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - loss: 0.0039 - mean_absolute_error: 0.0296 - val_loss: 0.0022 - val_mean_absolute_error: 0.0254\n",
      "Epoch 128/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - loss: 0.0013 - mean_absolute_error: 0.0225 - val_loss: 0.0020 - val_mean_absolute_error: 0.0234\n",
      "Epoch 129/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - loss: 0.0016 - mean_absolute_error: 0.0243 - val_loss: 0.0019 - val_mean_absolute_error: 0.0234\n",
      "Epoch 130/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - loss: 0.0023 - mean_absolute_error: 0.0256 - val_loss: 0.0020 - val_mean_absolute_error: 0.0246\n",
      "Epoch 131/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0042 - mean_absolute_error: 0.0264 - val_loss: 0.0020 - val_mean_absolute_error: 0.0248\n",
      "Epoch 132/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0021 - mean_absolute_error: 0.0243 - val_loss: 0.0019 - val_mean_absolute_error: 0.0229\n",
      "Epoch 133/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0031 - mean_absolute_error: 0.0262 - val_loss: 0.0019 - val_mean_absolute_error: 0.0241\n",
      "Epoch 134/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 0.0032 - mean_absolute_error: 0.0275 - val_loss: 0.0018 - val_mean_absolute_error: 0.0233\n",
      "Epoch 135/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - loss: 0.0021 - mean_absolute_error: 0.0248 - val_loss: 0.0022 - val_mean_absolute_error: 0.0262\n",
      "Epoch 136/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - loss: 0.0020 - mean_absolute_error: 0.0251 - val_loss: 0.0021 - val_mean_absolute_error: 0.0254\n",
      "Epoch 137/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0028 - mean_absolute_error: 0.0252 - val_loss: 0.0018 - val_mean_absolute_error: 0.0256\n",
      "Epoch 138/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0024 - mean_absolute_error: 0.0261 - val_loss: 0.0020 - val_mean_absolute_error: 0.0245\n",
      "Epoch 139/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0024 - mean_absolute_error: 0.0236 - val_loss: 0.0018 - val_mean_absolute_error: 0.0245\n",
      "Epoch 140/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0024 - mean_absolute_error: 0.0266 - val_loss: 0.0020 - val_mean_absolute_error: 0.0240\n",
      "Epoch 141/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0029 - mean_absolute_error: 0.0251 - val_loss: 0.0018 - val_mean_absolute_error: 0.0248\n",
      "Epoch 142/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.0034 - mean_absolute_error: 0.0254 - val_loss: 0.0018 - val_mean_absolute_error: 0.0225\n",
      "Epoch 143/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0030 - mean_absolute_error: 0.0244 - val_loss: 0.0018 - val_mean_absolute_error: 0.0233\n",
      "Epoch 144/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - loss: 0.0016 - mean_absolute_error: 0.0227 - val_loss: 0.0017 - val_mean_absolute_error: 0.0246\n",
      "Epoch 145/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 0.0032 - mean_absolute_error: 0.0272 - val_loss: 0.0019 - val_mean_absolute_error: 0.0247\n",
      "Epoch 146/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0024 - mean_absolute_error: 0.0250 - val_loss: 0.0023 - val_mean_absolute_error: 0.0265\n",
      "Epoch 147/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.0029 - mean_absolute_error: 0.0279 - val_loss: 0.0018 - val_mean_absolute_error: 0.0231\n",
      "Epoch 148/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - loss: 0.0028 - mean_absolute_error: 0.0257 - val_loss: 0.0018 - val_mean_absolute_error: 0.0232\n",
      "Epoch 149/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - loss: 0.0027 - mean_absolute_error: 0.0250 - val_loss: 0.0017 - val_mean_absolute_error: 0.0227\n",
      "Epoch 150/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0015 - mean_absolute_error: 0.0230 - val_loss: 0.0018 - val_mean_absolute_error: 0.0230\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0016 - mean_absolute_error: 0.0223\n",
      "Test Loss: 0.0017228754004463553, Test MAE: 0.022654326632618904\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test), batch_size=15, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "#model.save('../model_weights/CNN_padded_images.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
      "R2 Score:  0.5094366778419466\n"
     ]
    }
   ],
   "source": [
    "metric = tf.metrics.R2Score()\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "[[0.03780432]]\n"
     ]
    }
   ],
   "source": [
    "input_img = load_img(\"../data/padded_images/resized_p39.jpg\")\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "input_img = input_img.resize((img_width, img_height))\n",
    "img_array = img_to_array(input_img)\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "prediction = model.predict(img_array)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5121133270477398"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming y_true are the actual values and y_pred are the predictions from your model\n",
    "\n",
    "def round_to_nearest_25(values):\n",
    "    rounded_values = np.round(values * 4) / 4\n",
    "    return rounded_values\n",
    "\n",
    "metric = tf.metrics.R2Score()\n",
    "y_pred = model.predict(X_test)\n",
    "y_in = scaler.inverse_transform(y_pred)\n",
    "y_rounded = round_to_nearest_25(y_in)\n",
    "r2 = r2_score(y_test_un, y_rounded)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12729084372709687"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def round_to_nearest_25(values):\n",
    "    rounded_values = np.round(values * 4) / 4\n",
    "    return rounded_values\n",
    "\n",
    "metric = tf.metrics.R2Score()\n",
    "y_pred = model.predict(X_test)\n",
    "y_in = scaler.inverse_transform(y_pred)\n",
    "y_rounded = round_to_nearest_25(y_in)\n",
    "r2 = r2_score(y_test_un, y_rounded)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffanschoonbee/Documents/Studies/Hackathon/StandardBankHackathon/notebook/venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:562: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augment_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Augment</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61504</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,968,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augment_14 (\u001b[38;5;33mAugment\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_31 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m4,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_32 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61504\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m1,968,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,948,452</span> (15.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,948,452\u001b[0m (15.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,974,225</span> (7.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,974,225\u001b[0m (7.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,974,227</span> (7.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,974,227\u001b[0m (7.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('../model_weights/CNN_padded_images.keras', custom_objects={'Augment': Augment})\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ augment_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Augment</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ augment_16 (\u001b[38;5;33mAugment\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,721,473</span> (90.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,721,473\u001b[0m (90.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,549,313</span> (13.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,549,313\u001b[0m (13.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,172,160</span> (76.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,172,160\u001b[0m (76.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-7:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "augment_layer = Augment()\n",
    "# Input layer\n",
    "inputs = Input(shape=(256, 256, 3))\n",
    "\n",
    "# Add the augment layer\n",
    "x = augment_layer(inputs)\n",
    "\n",
    "# Pass the augmented images through the ResNet model\n",
    "x = base_model(x)\n",
    "\n",
    "# Add global pooling and custom layers\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=20,          # Stop after 5 epochs of no improvement\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best loss\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 618ms/step - loss: 0.1959 - mean_absolute_error: 0.2686 - val_loss: 0.0081 - val_mean_absolute_error: 0.0822\n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 603ms/step - loss: 0.0094 - mean_absolute_error: 0.0459 - val_loss: 0.0049 - val_mean_absolute_error: 0.0588\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 584ms/step - loss: 0.0080 - mean_absolute_error: 0.0408 - val_loss: 0.0045 - val_mean_absolute_error: 0.0405\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 582ms/step - loss: 0.0129 - mean_absolute_error: 0.0439 - val_loss: 0.0055 - val_mean_absolute_error: 0.0460\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 588ms/step - loss: 0.0109 - mean_absolute_error: 0.0462 - val_loss: 0.0036 - val_mean_absolute_error: 0.0355\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 588ms/step - loss: 0.0112 - mean_absolute_error: 0.0440 - val_loss: 0.0035 - val_mean_absolute_error: 0.0376\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 602ms/step - loss: 0.0086 - mean_absolute_error: 0.0428 - val_loss: 0.0033 - val_mean_absolute_error: 0.0375\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 598ms/step - loss: 0.0083 - mean_absolute_error: 0.0465 - val_loss: 0.0035 - val_mean_absolute_error: 0.0379\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 595ms/step - loss: 0.0071 - mean_absolute_error: 0.0421 - val_loss: 0.0035 - val_mean_absolute_error: 0.0384\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 586ms/step - loss: 0.0085 - mean_absolute_error: 0.0444 - val_loss: 0.0035 - val_mean_absolute_error: 0.0386\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 592ms/step - loss: 0.0078 - mean_absolute_error: 0.0428 - val_loss: 0.0035 - val_mean_absolute_error: 0.0389\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 599ms/step - loss: 0.0081 - mean_absolute_error: 0.0444 - val_loss: 0.0035 - val_mean_absolute_error: 0.0386\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 591ms/step - loss: 0.0074 - mean_absolute_error: 0.0413 - val_loss: 0.0036 - val_mean_absolute_error: 0.0414\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 586ms/step - loss: 0.0062 - mean_absolute_error: 0.0409 - val_loss: 0.0035 - val_mean_absolute_error: 0.0388\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 591ms/step - loss: 0.0074 - mean_absolute_error: 0.0413 - val_loss: 0.0031 - val_mean_absolute_error: 0.0372\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 596ms/step - loss: 0.0078 - mean_absolute_error: 0.0416 - val_loss: 0.0035 - val_mean_absolute_error: 0.0388\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 613ms/step - loss: 0.0054 - mean_absolute_error: 0.0407 - val_loss: 0.0035 - val_mean_absolute_error: 0.0388\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 605ms/step - loss: 0.0086 - mean_absolute_error: 0.0450 - val_loss: 0.0033 - val_mean_absolute_error: 0.0376\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 599ms/step - loss: 0.0074 - mean_absolute_error: 0.0431 - val_loss: 0.0033 - val_mean_absolute_error: 0.0378\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 590ms/step - loss: 0.0116 - mean_absolute_error: 0.0509 - val_loss: 0.0035 - val_mean_absolute_error: 0.0390\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 586ms/step - loss: 0.0071 - mean_absolute_error: 0.0416 - val_loss: 0.0035 - val_mean_absolute_error: 0.0392\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 585ms/step - loss: 0.0095 - mean_absolute_error: 0.0460 - val_loss: 0.0035 - val_mean_absolute_error: 0.0390\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 610ms/step - loss: 0.0058 - mean_absolute_error: 0.0413 - val_loss: 0.0035 - val_mean_absolute_error: 0.0391\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 622ms/step - loss: 0.0078 - mean_absolute_error: 0.0433 - val_loss: 0.0035 - val_mean_absolute_error: 0.0394\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 582ms/step - loss: 0.0079 - mean_absolute_error: 0.0452 - val_loss: 0.0035 - val_mean_absolute_error: 0.0394\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 581ms/step - loss: 0.0076 - mean_absolute_error: 0.0433 - val_loss: 0.0035 - val_mean_absolute_error: 0.0393\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 597ms/step - loss: 0.0052 - mean_absolute_error: 0.0390 - val_loss: 0.0035 - val_mean_absolute_error: 0.0396\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 594ms/step - loss: 0.0099 - mean_absolute_error: 0.0501 - val_loss: 0.0034 - val_mean_absolute_error: 0.0388\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 601ms/step - loss: 0.0079 - mean_absolute_error: 0.0434 - val_loss: 0.0035 - val_mean_absolute_error: 0.0392\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 588ms/step - loss: 0.0085 - mean_absolute_error: 0.0443 - val_loss: 0.0035 - val_mean_absolute_error: 0.0394\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 588ms/step - loss: 0.0103 - mean_absolute_error: 0.0473 - val_loss: 0.0035 - val_mean_absolute_error: 0.0393\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 591ms/step - loss: 0.0098 - mean_absolute_error: 0.0472 - val_loss: 0.0035 - val_mean_absolute_error: 0.0394\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 586ms/step - loss: 0.0095 - mean_absolute_error: 0.0456 - val_loss: 0.0035 - val_mean_absolute_error: 0.0394\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 591ms/step - loss: 0.0090 - mean_absolute_error: 0.0452 - val_loss: 0.0035 - val_mean_absolute_error: 0.0392\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 590ms/step - loss: 0.0095 - mean_absolute_error: 0.0451 - val_loss: 0.0035 - val_mean_absolute_error: 0.0392\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=15,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 890ms/step\n",
      "R2 Score:  0.10469072408692237\n"
     ]
    }
   ],
   "source": [
    "metric = tf.metrics.R2Score()\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file names: ['p1156.jpg' 'p154.jpg' 'p245.jpg' 'p928.jpg' 'p1121.jpg' 'p1655.jpg'\n",
      " 'p1038.jpg' 'p963.jpg' 'p1515.jpg' 'p294.jpg' 'p1080.jpg' 'p1248.jpg'\n",
      " 'p1264.jpg' 'p1232.jpg' 'p1586.jpg' 'p420.jpg' 'p39.jpg' 'p423.jpg'\n",
      " 'p1291.jpg' 'p460.jpg' 'p1267.jpg' 'p135.jpg' 'p284.jpg' 'p1613.jpg'\n",
      " 'p1212.jpg' 'p928.jpg' 'p974.jpg' 'p1081.jpg' 'p454.jpg' 'p422.jpg'\n",
      " 'p1144.jpg' 'p124.jpg' 'p1246.jpg' 'p1571.jpg' 'p69.jpg' 'p1179.jpg'\n",
      " 'p1602.jpg' 'p972.jpg' 'p426.jpg' 'p1577.jpg' 'p1168.jpg' 'p52.jpg'\n",
      " 'p1271.jpg' 'p1049.jpg' 'p943.jpg' 'p499.jpg' 'p1563.jpg' 'p996.jpg'\n",
      " 'p291.jpg' 'p940.jpg' 'p1527.jpg' 'p271.jpg' 'p979.jpg' 'p456.jpg'\n",
      " 'p1619.jpg' 'p192.jpg' 'p498.jpg' 'p476.jpg' 'p1586.jpg' 'p1140.jpg'\n",
      " 'p1551.jpg' 'p1560.jpg' 'p1017.jpg' 'p278.jpg' 'p1259.jpg' 'p1667.jpg'\n",
      " 'p276.jpg' 'p1190.jpg' 'p197.jpg' 'p283.jpg' 'p1049.jpg' 'p1344.jpg'\n",
      " 'p184.jpg' 'p1123.jpg' 'p1187.jpg' 'p935.jpg' 'p932.jpg' 'p933.jpg'\n",
      " 'p174.jpg' 'p1588.jpg' 'p296.jpg' 'p949.jpg' 'p1098.jpg' 'p439.jpg'\n",
      " 'p1568.jpg' 'p216.jpg' 'p979.jpg' 'p1615.jpg' 'p1554.jpg' 'p998.jpg'\n",
      " 'p443.jpg' 'p1538.jpg' 'p1148.jpg' 'p1167.jpg' 'p425.jpg' 'p1235.jpg'\n",
      " 'p1294.jpg' 'p1303.jpg' 'p122.jpg' 'p1111.jpg' 'p141.jpg' 'p1321.jpg'\n",
      " 'p200.jpg' 'p414.jpg' 'p1266.jpg' 'p1540.jpg' 'p1073.jpg' 'p229.jpg'\n",
      " 'p1569.jpg' 'p994.jpg' 'p447.jpg' 'p118.jpg' 'p1023.jpg' 'p117.jpg'\n",
      " 'p415.jpg' 'p1233.jpg' 'p253.jpg' 'p993.jpg' 'p235.jpg' 'p177.jpg'\n",
      " 'p298.jpg' 'p267.jpg' 'p1041.jpg' 'p1445.jpg' 'p980.jpg' 'p1552.jpg'\n",
      " 'p1256.jpg' 'p1140.jpg' 'p1615.jpg' 'p1092.jpg' 'p937.jpg' 'p1324.jpg'\n",
      " 'p231.jpg' 'p1681.jpg' 'p1556.jpg' 'p1277.jpg' 'p1170.jpg' 'p162.jpg'\n",
      " 'p263.jpg' 'p1269.jpg' 'p267.jpg' 'p292.jpg' 'p1197.jpg' 'p1304.jpg'\n",
      " 'p1671.jpg' 'p1097.jpg' 'p86.jpg' 'p433.jpg' 'p71.jpg' 'p414.jpg'\n",
      " 'p247.jpg' 'p259.jpg' 'p1076.jpg' 'p1343.jpg' 'p1522.jpg' 'p1408.jpg'\n",
      " 'p277.jpg' 'p1176.jpg' 'p1224.jpg' 'p1522.jpg' 'p934.jpg' 'p1544.jpg'\n",
      " 'p1542.jpg' 'p1596.jpg' 'p1570.jpg' 'p191.jpg' 'p1585.jpg' 'p290.jpg'\n",
      " 'p1099.jpg' 'p431.jpg' 'p1041.jpg' 'p140.jpg' 'p225.jpg' 'p456.jpg'\n",
      " 'p1433.jpg' 'p1042.jpg' 'p452.jpg' 'p477.jpg' 'p1147.jpg' 'p1564.jpg'\n",
      " 'p1502.jpg' 'p1658.jpg' 'p1613.jpg' 'p1620.jpg' 'p1604.jpg' 'p1532.jpg'\n",
      " 'p1293.jpg' 'p1563.jpg' 'p278.jpg' 'p1572.jpg' 'p1024.jpg' 'p1298.jpg'\n",
      " 'p165.jpg' 'p941.jpg' 'p1272.jpg' 'p172.jpg' 'p138.jpg' 'p65.jpg'\n",
      " 'p1619.jpg' 'p141.jpg' 'p1216.jpg' 'p1021.jpg' 'p1011.jpg' 'p1431.jpg'\n",
      " 'p441.jpg' 'p1102.jpg' 'p1589.jpg' 'p1176.jpg' 'p1119.jpg' 'p1539.jpg'\n",
      " 'p1431.jpg' 'p198.jpg' 'p997.jpg' 'p1620.jpg' 'p90.jpg' 'p1343.jpg'\n",
      " 'p1225.jpg' 'p958.jpg' 'p256.jpg' 'p1078.jpg' 'p166.jpg' 'p1107.jpg'\n",
      " 'p468.jpg' 'p1309.jpg' 'p970.jpg' 'p1509.jpg' 'p1579.jpg' 'p156.jpg'\n",
      " 'p1274.jpg' 'p1610.jpg' 'p1651.jpg' 'p1075.jpg' 'p970.jpg' 'p1326.jpg'\n",
      " 'p61.jpg' 'p992.jpg' 'p175.jpg' 'p297.jpg' 'p1221.jpg' 'p940.jpg'\n",
      " 'p1257.jpg' 'p1109.jpg' 'p155.jpg' 'p929.jpg' 'p178.jpg' 'p986.jpg'\n",
      " 'p1164.jpg' 'p251.jpg' 'p1608.jpg' 'p1556.jpg' 'p68.jpg' 'p236.jpg'\n",
      " 'p993.jpg' 'p1595.jpg' 'p1503.jpg' 'p288.jpg' 'p243.jpg' 'p157.jpg'\n",
      " 'p163.jpg' 'p65.jpg' 'p1207.jpg' 'p147.jpg' 'p248.jpg' 'p69.jpg'\n",
      " 'p1039.jpg' 'p1625.jpg' 'p1106.jpg' 'p1540.jpg' 'p179.jpg' 'p943.jpg'\n",
      " 'p1356.jpg' 'p1104.jpg' 'p291.jpg' 'p269.jpg' 'p451.jpg' 'p1061.jpg'\n",
      " 'p1157.jpg' 'p1229.jpg' 'p178.jpg' 'p1201.jpg' 'p1445.jpg' 'p1600.jpg'\n",
      " 'p1228.jpg' 'p1170.jpg' 'p50.jpg' 'p974.jpg' 'p241.jpg' 'p155.jpg'\n",
      " 'p132.jpg' 'p173.jpg' 'p1597.jpg' 'p1565.jpg' 'p54.jpg' 'p1644.jpg'\n",
      " 'p1418.jpg' 'p1111.jpg' 'p1130.jpg' 'p234.jpg' 'p112.jpg' 'p47.jpg'\n",
      " 'p1511.jpg' 'p193.jpg' 'p1320.jpg' 'p57.jpg']\n"
     ]
    }
   ],
   "source": [
    "X = np.array([preprocess_image('../data/padded_images/resized_' + file) for file in valid_df['img_file']])\n",
    "y = valid_df['Bags used '].values\n",
    "file_names = valid_df['img_file'].values  # Get the file names\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train_un, y_test_un, train_files, test_files = train_test_split(X, y, file_names, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[[0.03983825]]\n"
     ]
    }
   ],
   "source": [
    "input_img = load_img(\"../data/padded_images/resized_p142.jpg\")\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "input_img = input_img.resize((img_width, img_height))\n",
    "img_array = img_to_array(input_img)\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "loaded_model = tf.keras.models.load_model('../model_weights/CNN_padded_images.keras', custom_objects={'Augment': Augment})\n",
    "prediction = loaded_model.predict(img_array)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
